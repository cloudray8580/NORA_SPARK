{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init() # this must be executed before the below import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import rtree\n",
    "from rtree import index\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from multiprocessing import Pool\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DRProcess import *\n",
    "from DDProcess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAll([(\"spark.executor.memory\", \"8g\"),(\"spark.driver.memory\",\"8g\"),\n",
    "                           (\"spark.memory.offHeap.enabled\",True),(\"spark.memory.offHeap.size\",\"8g\")])\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.app.id', 'local-1603446495505'),\n",
       " ('spark.memory.offHeap.size', '8g'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.name', 'pyspark-shell'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.driver.memory', '8g'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.executor.memory', '8g'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.driver.host', 'namenode.novalocal'),\n",
       " ('spark.memory.offHeap.enabled', 'True'),\n",
       " ('spark.driver.port', '42310'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DumpThread(threading.Thread):\n",
    "    def __init__(self, thread_id, name, parameters):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.thread_id = thread_id\n",
    "        self.name = name\n",
    "        self.parameters = parameters\n",
    "        \n",
    "    def run(self):\n",
    "        print('start dumping thread: ', self.thread_id, self.name)\n",
    "        start_index, end_index, pids, pid_data_dict, hdfs_path, column_names = self.parameters\n",
    "        for pid in pids[start_index: end_index]:\n",
    "            path = hdfs_path + 'partition_' + str(pid)+'.parquet'\n",
    "            pdf = pd.DataFrame(pid_data_dict[pid], columns=column_names)\n",
    "            df = sqlContext.createDataFrame(pdf)\n",
    "            df.write.mode('append').parquet(path)\n",
    "            pid_data_dict[pid] = []\n",
    "        print('exit dumping thread: ', self.thread_id, self.name)\n",
    "        \n",
    "def dump_dict_data_2_hdfs(pid_data_dicts, column_names, hdfs_path, num_threads = 8):\n",
    "    \n",
    "    # first merge all the dicts\n",
    "    base_dict = pid_data_dicts[0]\n",
    "    for k in range(1, len(pid_data_dicts)):\n",
    "        for key, val in pid_data_dicts[k].items():\n",
    "            if key in base_dict:\n",
    "                base_dict[key] += val\n",
    "            else:\n",
    "                base_dict.update({key:val})\n",
    "        pid_data_dicts[k].clear()\n",
    "    \n",
    "    if num_threads == 1:\n",
    "        print('start dumping single thread (main)')\n",
    "        pids = list(base_dict.keys())\n",
    "        for pid in pids:\n",
    "            path = hdfs_path + 'partition_' + str(pid)+'.parquet'\n",
    "            pdf = pd.DataFrame(base_dict[pid], columns=column_names)\n",
    "            df = sqlContext.createDataFrame(pdf)\n",
    "            df.write.mode('append').parquet(path)\n",
    "            base_dict[pid] = []\n",
    "        print('finish dumping single thread (main)')\n",
    "    \n",
    "    else:\n",
    "        # apply multi-threading to save\n",
    "        pids = list(base_dict.keys())\n",
    "        step = int(len(pids) / num_threads) + 1\n",
    "        threads = []\n",
    "        for i in range(num_threads):\n",
    "            start_index = i * step\n",
    "            end_index = (i+1) * step\n",
    "            parameters = [start_index, end_index, pids, base_dict, hdfs_path, column_names]\n",
    "            thread = DumpThread(i, 'dump_thread_'+str(i), parameters)\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "            if start_index >= len(pids):\n",
    "                break   \n",
    "        for t in threads:\n",
    "            t.join()\n",
    "\n",
    "# used for multi-process wirting\n",
    "def merge_dicts(pid_data_dicts, num_process):\n",
    "    base_dict = pid_data_dicts[0]\n",
    "    for k in range(1, len(pid_data_dicts)):\n",
    "        for key, val in pid_data_dicts[k].items():\n",
    "            if key in base_dict:\n",
    "                base_dict[key] += val\n",
    "            else:\n",
    "                base_dict.update({key:val})\n",
    "        pid_data_dicts[k].clear()\n",
    "    \n",
    "    # re allocate to non-overlap dicts\n",
    "    pids = list(base_dict.keys())\n",
    "    step = int(len(pids) / num_process) + 1\n",
    "    non_overlap_dicts = [{} for i in range(num_process)]\n",
    "    \n",
    "    for key, val in base_dict.items():\n",
    "        dict_index = key // step\n",
    "        non_overlap_dicts[dict_index][key] = val\n",
    "        \n",
    "    return non_overlap_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data_parallel(table_path, partition_path, chunk_size, used_dims, hdfs_path, \n",
    "                        num_dims, dump_threshold = 1000000, num_process = 8):\n",
    "    \n",
    "    begin_time = time.time()\n",
    "    \n",
    "    col_names = ['_c'+str(i) for i in range(num_dims)]\n",
    "    cols = [i for i in range(num_dims)]\n",
    "    \n",
    "    pid_data_dicts = []\n",
    "    for i in range(num_process):\n",
    "        pid_data_dicts.append({})\n",
    "    \n",
    "    chunks = []\n",
    "    \n",
    "    count = 0\n",
    "    epochs = 0\n",
    "    processed_data = 0\n",
    "    pool = Pool(processes = num_process) # the pool should be reused, or incur memory leak!\n",
    "    pids_each_process = [set() for k in range(num_process)] # used for final merge\n",
    "    \n",
    "    for chunk in pd.read_table(table_path, delimiter='|', usecols=cols, names=col_names, chunksize=chunk_size):\n",
    "    #for chunk in pd.read_csv(table_path, usecols=cols, names=col_names, chunksize=chunk_size):\n",
    "        print('current chunk: ', count)\n",
    "        chunks.append(chunk)\n",
    "        if count % num_process == num_process - 1:\n",
    "            paras = [[chunks[k], used_dims, partition_path, pid_data_dicts[k]] for k in range(num_process)]\n",
    "            pid_data_dicts = pool.map(process_chunk, [para for para in paras])\n",
    "            print('===================')\n",
    "            chunks = []\n",
    "            processed_data += chunk_size * num_process\n",
    "            \n",
    "            # dump data to file\n",
    "            if processed_data >= dump_threshold:\n",
    "                print(\"= = = dumping epoch:\", epochs, \"= = =\")\n",
    "                # parquet write is not thread safe, avoid concurent write\n",
    "                pid_data_dicts = merge_dicts(pid_data_dicts, num_process) # make it non-overlap\n",
    "                for k in range(num_process):\n",
    "                    pids_each_process[k].update(list(pid_data_dicts[k].keys()))\n",
    "                paras = [[epochs, pid_data_dicts[k], col_names, hdfs_path] for k in range(num_process)]\n",
    "                pool.map(dump_data, [para for para in paras])\n",
    "                #dump_dict_data_2_hdfs(pid_data_dicts, col_names, hdfs_path) # multi-thread\n",
    "                processed_data = 0\n",
    "                epochs += 1\n",
    "                for i in range(num_process):\n",
    "                    pid_data_dicts[i].clear()\n",
    "        count += 1\n",
    "        \n",
    "    dict_size = [len(pid_data_dicts[i]) for i in range(num_process)]\n",
    "    print('after exit, chunks size: ', len(chunks))\n",
    "    print('after exit, each dict size: ', dict_size)\n",
    "    # process the last batch\n",
    "    if len(chunks) != 0:\n",
    "        paras = [[chunks[k], used_dims, partition_path, pid_data_dicts[k]] for k in range(len(chunks))]\n",
    "        pid_data_dicts[0:len(chunks)] = pool.map(process_chunk, [para for para in paras])\n",
    "    \n",
    "    \n",
    "    dict_size = [len(pid_data_dicts[i]) for i in range(num_process)]\n",
    "    print('after last chunk, each dict size: ', dict_size)\n",
    "    \n",
    "    if len(pid_data_dicts[0]) != 0:\n",
    "        pid_data_dicts = merge_dicts(pid_data_dicts, num_process) # make it non-overlap\n",
    "        paras = [[epochs, pid_data_dicts[k], col_names, hdfs_path] for k in range(num_process)]\n",
    "        pool.map(dump_data, [para for para in paras])\n",
    "        #dump_dict_data_2_hdfs(pid_data_dicts, col_names, hdfs_path)\n",
    "        for k in range(num_process):\n",
    "            pids_each_process[k].update(list(pid_data_dicts[k].keys()))\n",
    "    \n",
    "    pid_data_dicts.clear() # release memory\n",
    "    \n",
    "    # final merge\n",
    "    epochs += 1\n",
    "    paras = [[epochs, pids_each_process[k], hdfs_path] for k in range(num_process)]\n",
    "    pool.map(merge_parquets, [para for para in paras])\n",
    "        \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    finish_time = time.time()\n",
    "    print('total data routing and persisting time: ', finish_time - begin_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # = = = Configuration (COMP Cloud Ubuntu) = = =\n",
    "# scale_factor = 100\n",
    "\n",
    "# table_base_path = '/home/ubuntu/TPCH/dbgen/'\n",
    "# table_path = table_base_path + 'lineitem_' + str(scale_factor) + '.tbl'\n",
    "\n",
    "# num_process = 12\n",
    "# chunk_size = 200000\n",
    "# dump_threshold = 12000000 # 6M rows = about 1GB raw data\n",
    "\n",
    "# num_dims = 16\n",
    "# used_dims = [1,2]\n",
    "\n",
    "# # base path of HDFS\n",
    "# hdfs_base_path = 'hdfs://10.88.88.103:9000/user/cloudray/'\n",
    "\n",
    "# nora_hdfs = hdfs_base_path + 'NORA/scale' + str(scale_factor) + '/'\n",
    "# qdtree_hdfs = hdfs_base_path + 'QdTree/scale' + str(scale_factor) + '/'\n",
    "# kdtree_hdfs = hdfs_base_path + 'KDTree/scale' + str(scale_factor) + '/'\n",
    "\n",
    "# # base path of Partition\n",
    "# partition_base_path = '/home/ubuntu/PartitionLayout/'\n",
    "\n",
    "# nora_partition = partition_base_path + 'nora_partitions_' + str(scale_factor)\n",
    "# qdtree_partition = partition_base_path + 'qdtree_partitions_' + str(scale_factor)\n",
    "# kdtree_partition = partition_base_path + 'kdt_partitions_' + str(scale_factor)\n",
    "\n",
    "# # Legacy\n",
    "# # table_path = '/home/cloudray/Downloads/TPCH_12M_8Field.csv'\n",
    "# # table_path = '/home/cloudray/TPCH/2.18.0_rc2/dbgen/lineitem.tbl'\n",
    "\n",
    "# # partition_path = '/home/cloudray/NORA_Partitions/nora_partitions'\n",
    "# # partition_path = '/home/cloudray/NORA_Partitions/qd_tree_partitions'\n",
    "\n",
    "# # hdfs_path = 'hdfs://localhost:9000/user/cloudray/NORA/'\n",
    "# # hdfs_path = 'hdfs://localhost:9000/user/cloudray/QdTree/'\n",
    "\n",
    "# # partition_path = '/home/cloudray/NORA_Partitions/nora_test'\n",
    "# # partition_path = '/home/cloudray/NORA_Partitions/qd_tree_test'\n",
    "\n",
    "# # hdfs_path = 'hdfs://localhost:9000/user/cloudray/NORA_Test/'\n",
    "# # hdfs_path = 'hdfs://localhost:9000/user/cloudray/QdTree_Test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# = = = Configuration (UBDA Cloud Centos) = = =\n",
    "scale_factor = 100\n",
    "\n",
    "table_base_path = '/media/datadrive1/TPCH/dbgen/'\n",
    "table_path = table_base_path + 'lineitem_' + str(scale_factor) + '.tbl'\n",
    "\n",
    "num_process = 8\n",
    "chunk_size = 3000000\n",
    "dump_threshold = 24000000 # 6M rows = about 1GB raw data, each dump includes 4G data\n",
    "\n",
    "num_dims = 16\n",
    "used_dims = [1,2]\n",
    "\n",
    "# base path of HDFS\n",
    "hdfs_base_path = 'hdfs://192.168.6.62:9000/user/centos/'\n",
    "\n",
    "nora_hdfs = hdfs_base_path + 'NORA/scale' + str(scale_factor) + '/'\n",
    "qdtree_hdfs = hdfs_base_path + 'QdTree/scale' + str(scale_factor) + '/'\n",
    "kdtree_hdfs = hdfs_base_path + 'KDTree/scale' + str(scale_factor) + '/'\n",
    "\n",
    "# base path of Partition\n",
    "partition_base_path = '/home/centos/PartitionLayout/'\n",
    "\n",
    "nora_partition = partition_base_path + 'nora_partitions_' + str(scale_factor)\n",
    "qdtree_partition = partition_base_path + 'qdtree_partitions_' + str(scale_factor)\n",
    "kdtree_partition = partition_base_path + 'kdt_partitions_' + str(scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current chunk:  0\n",
      "current chunk:  1\n",
      "current chunk:  2\n",
      "current chunk:  3\n",
      "current chunk:  4\n",
      "current chunk:  5\n",
      "current chunk:  6\n",
      "current chunk:  7\n",
      "===================\n",
      "current chunk:  8\n",
      "current chunk:  9\n",
      "current chunk:  10\n",
      "current chunk:  11\n",
      "current chunk:  12\n",
      "current chunk:  13\n",
      "current chunk:  14\n",
      "current chunk:  15\n",
      "===================\n",
      "current chunk:  16\n",
      "current chunk:  17\n",
      "current chunk:  18\n",
      "current chunk:  19\n",
      "current chunk:  20\n",
      "current chunk:  21\n",
      "current chunk:  22\n",
      "current chunk:  23\n",
      "===================\n",
      "current chunk:  24\n",
      "current chunk:  25\n",
      "current chunk:  26\n",
      "current chunk:  27\n",
      "current chunk:  28\n",
      "current chunk:  29\n",
      "current chunk:  30\n",
      "current chunk:  31\n",
      "===================\n",
      "current chunk:  32\n",
      "current chunk:  33\n",
      "current chunk:  34\n",
      "current chunk:  35\n",
      "current chunk:  36\n",
      "current chunk:  37\n",
      "current chunk:  38\n",
      "current chunk:  39\n",
      "===================\n",
      "current chunk:  40\n",
      "current chunk:  41\n",
      "current chunk:  42\n",
      "current chunk:  43\n",
      "current chunk:  44\n",
      "current chunk:  45\n",
      "current chunk:  46\n",
      "current chunk:  47\n",
      "===================\n",
      "current chunk:  48\n",
      "current chunk:  49\n",
      "current chunk:  50\n",
      "current chunk:  51\n",
      "current chunk:  52\n",
      "current chunk:  53\n",
      "current chunk:  54\n",
      "current chunk:  55\n",
      "===================\n",
      "current chunk:  56\n",
      "current chunk:  57\n",
      "current chunk:  58\n",
      "current chunk:  59\n",
      "current chunk:  60\n",
      "current chunk:  61\n",
      "current chunk:  62\n",
      "current chunk:  63\n",
      "===================\n",
      "current chunk:  64\n",
      "current chunk:  65\n",
      "current chunk:  66\n",
      "current chunk:  67\n",
      "current chunk:  68\n",
      "current chunk:  69\n",
      "current chunk:  70\n",
      "current chunk:  71\n",
      "===================\n",
      "current chunk:  72\n",
      "current chunk:  73\n",
      "current chunk:  74\n",
      "current chunk:  75\n",
      "current chunk:  76\n",
      "current chunk:  77\n",
      "current chunk:  78\n",
      "current chunk:  79\n",
      "===================\n",
      "current chunk:  80\n",
      "current chunk:  81\n",
      "current chunk:  82\n",
      "current chunk:  83\n",
      "current chunk:  84\n",
      "current chunk:  85\n",
      "current chunk:  86\n",
      "current chunk:  87\n",
      "===================\n",
      "current chunk:  88\n",
      "current chunk:  89\n",
      "current chunk:  90\n",
      "current chunk:  91\n",
      "current chunk:  92\n",
      "current chunk:  93\n",
      "current chunk:  94\n",
      "current chunk:  95\n",
      "===================\n",
      "current chunk:  96\n",
      "current chunk:  97\n",
      "current chunk:  98\n",
      "current chunk:  99\n",
      "current chunk:  100\n",
      "current chunk:  101\n",
      "current chunk:  102\n",
      "current chunk:  103\n",
      "===================\n",
      "current chunk:  104\n",
      "current chunk:  105\n",
      "current chunk:  106\n",
      "current chunk:  107\n",
      "current chunk:  108\n",
      "current chunk:  109\n",
      "current chunk:  110\n",
      "current chunk:  111\n",
      "===================\n",
      "current chunk:  112\n",
      "current chunk:  113\n",
      "current chunk:  114\n",
      "current chunk:  115\n",
      "current chunk:  116\n",
      "current chunk:  117\n",
      "current chunk:  118\n",
      "current chunk:  119\n",
      "===================\n",
      "current chunk:  120\n",
      "current chunk:  121\n",
      "current chunk:  122\n",
      "current chunk:  123\n",
      "current chunk:  124\n",
      "current chunk:  125\n",
      "current chunk:  126\n",
      "current chunk:  127\n",
      "===================\n",
      "current chunk:  128\n",
      "current chunk:  129\n",
      "current chunk:  130\n",
      "current chunk:  131\n",
      "current chunk:  132\n",
      "current chunk:  133\n",
      "current chunk:  134\n",
      "current chunk:  135\n",
      "===================\n",
      "current chunk:  136\n",
      "current chunk:  137\n",
      "current chunk:  138\n",
      "current chunk:  139\n",
      "current chunk:  140\n",
      "current chunk:  141\n",
      "current chunk:  142\n",
      "current chunk:  143\n",
      "===================\n",
      "current chunk:  144\n",
      "current chunk:  145\n",
      "current chunk:  146\n",
      "current chunk:  147\n",
      "current chunk:  148\n",
      "current chunk:  149\n",
      "current chunk:  150\n",
      "current chunk:  151\n",
      "===================\n",
      "current chunk:  152\n",
      "current chunk:  153\n",
      "current chunk:  154\n",
      "current chunk:  155\n",
      "current chunk:  156\n",
      "current chunk:  157\n",
      "current chunk:  158\n",
      "current chunk:  159\n",
      "===================\n",
      "= = = dumping epoch: 0 = = =\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "current chunk:  160\n",
      "current chunk:  161\n",
      "current chunk:  162\n",
      "current chunk:  163\n",
      "current chunk:  164\n",
      "current chunk:  165\n",
      "current chunk:  166\n",
      "current chunk:  167\n",
      "===================\n",
      "current chunk:  168\n",
      "current chunk:  169\n",
      "current chunk:  170\n",
      "current chunk:  171\n",
      "current chunk:  172\n",
      "current chunk:  173\n",
      "current chunk:  174\n",
      "current chunk:  175\n",
      "===================\n",
      "current chunk:  176\n",
      "current chunk:  177\n",
      "current chunk:  178\n",
      "current chunk:  179\n",
      "current chunk:  180\n",
      "current chunk:  181\n",
      "current chunk:  182\n",
      "current chunk:  183\n",
      "===================\n",
      "current chunk:  184\n",
      "current chunk:  185\n",
      "current chunk:  186\n",
      "current chunk:  187\n",
      "current chunk:  188\n",
      "current chunk:  189\n",
      "current chunk:  190\n",
      "current chunk:  191\n",
      "===================\n",
      "current chunk:  192\n",
      "current chunk:  193\n",
      "current chunk:  194\n",
      "current chunk:  195\n",
      "current chunk:  196\n",
      "current chunk:  197\n",
      "current chunk:  198\n",
      "current chunk:  199\n",
      "===================\n",
      "current chunk:  200\n",
      "current chunk:  201\n",
      "current chunk:  202\n",
      "current chunk:  203\n",
      "current chunk:  204\n",
      "current chunk:  205\n",
      "current chunk:  206\n",
      "current chunk:  207\n",
      "===================\n",
      "current chunk:  208\n",
      "current chunk:  209\n",
      "current chunk:  210\n",
      "current chunk:  211\n",
      "current chunk:  212\n",
      "current chunk:  213\n",
      "current chunk:  214\n",
      "current chunk:  215\n",
      "===================\n",
      "current chunk:  216\n",
      "current chunk:  217\n",
      "current chunk:  218\n",
      "current chunk:  219\n",
      "current chunk:  220\n",
      "current chunk:  221\n",
      "current chunk:  222\n",
      "current chunk:  223\n",
      "===================\n",
      "current chunk:  224\n",
      "current chunk:  225\n",
      "current chunk:  226\n",
      "current chunk:  227\n",
      "current chunk:  228\n",
      "current chunk:  229\n",
      "current chunk:  230\n",
      "current chunk:  231\n",
      "===================\n",
      "current chunk:  232\n",
      "current chunk:  233\n",
      "current chunk:  234\n",
      "current chunk:  235\n",
      "current chunk:  236\n",
      "current chunk:  237\n",
      "current chunk:  238\n",
      "current chunk:  239\n",
      "===================\n",
      "current chunk:  240\n",
      "current chunk:  241\n",
      "current chunk:  242\n",
      "current chunk:  243\n",
      "current chunk:  244\n",
      "current chunk:  245\n",
      "current chunk:  246\n",
      "current chunk:  247\n",
      "===================\n",
      "current chunk:  248\n",
      "current chunk:  249\n",
      "current chunk:  250\n",
      "current chunk:  251\n",
      "current chunk:  252\n",
      "current chunk:  253\n",
      "current chunk:  254\n",
      "current chunk:  255\n",
      "===================\n",
      "current chunk:  256\n",
      "current chunk:  257\n",
      "current chunk:  258\n",
      "current chunk:  259\n",
      "current chunk:  260\n",
      "current chunk:  261\n",
      "current chunk:  262\n",
      "current chunk:  263\n",
      "===================\n",
      "current chunk:  264\n",
      "current chunk:  265\n",
      "current chunk:  266\n",
      "current chunk:  267\n",
      "current chunk:  268\n",
      "current chunk:  269\n",
      "current chunk:  270\n",
      "current chunk:  271\n",
      "===================\n",
      "current chunk:  272\n",
      "current chunk:  273\n",
      "current chunk:  274\n",
      "current chunk:  275\n",
      "current chunk:  276\n",
      "current chunk:  277\n",
      "current chunk:  278\n",
      "current chunk:  279\n",
      "===================\n",
      "current chunk:  280\n",
      "current chunk:  281\n",
      "current chunk:  282\n",
      "current chunk:  283\n",
      "current chunk:  284\n",
      "current chunk:  285\n",
      "current chunk:  286\n",
      "current chunk:  287\n",
      "===================\n",
      "current chunk:  288\n",
      "current chunk:  289\n",
      "current chunk:  290\n",
      "current chunk:  291\n",
      "current chunk:  292\n",
      "current chunk:  293\n",
      "current chunk:  294\n",
      "current chunk:  295\n",
      "===================\n",
      "current chunk:  296\n",
      "current chunk:  297\n",
      "current chunk:  298\n",
      "current chunk:  299\n",
      "current chunk:  300\n",
      "current chunk:  301\n",
      "current chunk:  302\n",
      "current chunk:  303\n",
      "===================\n",
      "current chunk:  304\n",
      "current chunk:  305\n",
      "current chunk:  306\n",
      "current chunk:  307\n",
      "current chunk:  308\n",
      "current chunk:  309\n",
      "current chunk:  310\n",
      "current chunk:  311\n",
      "===================\n",
      "current chunk:  312\n",
      "current chunk:  313\n",
      "current chunk:  314\n",
      "current chunk:  315\n",
      "current chunk:  316\n",
      "current chunk:  317\n",
      "current chunk:  318\n",
      "current chunk:  319\n",
      "===================\n",
      "= = = dumping epoch: 1 = = =\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "current chunk:  320\n",
      "current chunk:  321\n",
      "current chunk:  322\n",
      "current chunk:  323\n",
      "current chunk:  324\n",
      "current chunk:  325\n",
      "current chunk:  326\n",
      "current chunk:  327\n",
      "===================\n",
      "current chunk:  328\n",
      "current chunk:  329\n",
      "current chunk:  330\n",
      "current chunk:  331\n",
      "current chunk:  332\n",
      "current chunk:  333\n",
      "current chunk:  334\n",
      "current chunk:  335\n",
      "===================\n",
      "current chunk:  336\n",
      "current chunk:  337\n",
      "current chunk:  338\n",
      "current chunk:  339\n",
      "current chunk:  340\n",
      "current chunk:  341\n",
      "current chunk:  342\n",
      "current chunk:  343\n",
      "===================\n",
      "current chunk:  344\n",
      "current chunk:  345\n",
      "current chunk:  346\n",
      "current chunk:  347\n",
      "current chunk:  348\n",
      "current chunk:  349\n",
      "current chunk:  350\n",
      "current chunk:  351\n",
      "===================\n",
      "current chunk:  352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current chunk:  353\n",
      "current chunk:  354\n",
      "current chunk:  355\n",
      "current chunk:  356\n",
      "current chunk:  357\n",
      "current chunk:  358\n",
      "current chunk:  359\n",
      "===================\n",
      "current chunk:  360\n",
      "current chunk:  361\n",
      "current chunk:  362\n",
      "current chunk:  363\n",
      "current chunk:  364\n",
      "current chunk:  365\n",
      "current chunk:  366\n",
      "current chunk:  367\n",
      "===================\n",
      "current chunk:  368\n",
      "current chunk:  369\n",
      "current chunk:  370\n",
      "current chunk:  371\n",
      "current chunk:  372\n",
      "current chunk:  373\n",
      "current chunk:  374\n",
      "current chunk:  375\n",
      "===================\n",
      "current chunk:  376\n",
      "current chunk:  377\n",
      "current chunk:  378\n",
      "current chunk:  379\n",
      "current chunk:  380\n",
      "current chunk:  381\n",
      "current chunk:  382\n",
      "current chunk:  383\n",
      "===================\n",
      "current chunk:  384\n",
      "current chunk:  385\n",
      "current chunk:  386\n",
      "current chunk:  387\n",
      "current chunk:  388\n",
      "current chunk:  389\n",
      "current chunk:  390\n",
      "current chunk:  391\n",
      "===================\n",
      "current chunk:  392\n",
      "current chunk:  393\n",
      "current chunk:  394\n",
      "current chunk:  395\n",
      "current chunk:  396\n",
      "current chunk:  397\n",
      "current chunk:  398\n",
      "current chunk:  399\n",
      "===================\n",
      "current chunk:  400\n",
      "current chunk:  401\n",
      "current chunk:  402\n",
      "current chunk:  403\n",
      "current chunk:  404\n",
      "current chunk:  405\n",
      "current chunk:  406\n",
      "current chunk:  407\n",
      "===================\n",
      "current chunk:  408\n",
      "current chunk:  409\n",
      "current chunk:  410\n",
      "current chunk:  411\n",
      "current chunk:  412\n",
      "current chunk:  413\n",
      "current chunk:  414\n",
      "current chunk:  415\n",
      "===================\n",
      "current chunk:  416\n",
      "current chunk:  417\n",
      "current chunk:  418\n",
      "current chunk:  419\n",
      "current chunk:  420\n",
      "current chunk:  421\n",
      "current chunk:  422\n",
      "current chunk:  423\n",
      "===================\n",
      "current chunk:  424\n",
      "current chunk:  425\n",
      "current chunk:  426\n",
      "current chunk:  427\n",
      "current chunk:  428\n",
      "current chunk:  429\n",
      "current chunk:  430\n",
      "current chunk:  431\n",
      "===================\n",
      "current chunk:  432\n",
      "current chunk:  433\n",
      "current chunk:  434\n",
      "current chunk:  435\n",
      "current chunk:  436\n",
      "current chunk:  437\n",
      "current chunk:  438\n",
      "current chunk:  439\n",
      "===================\n",
      "current chunk:  440\n",
      "current chunk:  441\n",
      "current chunk:  442\n",
      "current chunk:  443\n",
      "current chunk:  444\n",
      "current chunk:  445\n",
      "current chunk:  446\n",
      "current chunk:  447\n",
      "===================\n",
      "current chunk:  448\n",
      "current chunk:  449\n",
      "current chunk:  450\n",
      "current chunk:  451\n",
      "current chunk:  452\n",
      "current chunk:  453\n",
      "current chunk:  454\n",
      "current chunk:  455\n",
      "===================\n",
      "current chunk:  456\n",
      "current chunk:  457\n",
      "current chunk:  458\n",
      "current chunk:  459\n",
      "current chunk:  460\n",
      "current chunk:  461\n",
      "current chunk:  462\n",
      "current chunk:  463\n",
      "===================\n",
      "current chunk:  464\n",
      "current chunk:  465\n",
      "current chunk:  466\n",
      "current chunk:  467\n",
      "current chunk:  468\n",
      "current chunk:  469\n",
      "current chunk:  470\n",
      "current chunk:  471\n",
      "===================\n",
      "current chunk:  472\n",
      "current chunk:  473\n",
      "current chunk:  474\n",
      "current chunk:  475\n",
      "current chunk:  476\n",
      "current chunk:  477\n",
      "current chunk:  478\n",
      "current chunk:  479\n",
      "===================\n",
      "= = = dumping epoch: 2 = = =\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "current chunk:  480\n",
      "current chunk:  481\n",
      "current chunk:  482\n",
      "current chunk:  483\n",
      "current chunk:  484\n",
      "current chunk:  485\n",
      "current chunk:  486\n",
      "current chunk:  487\n",
      "===================\n",
      "current chunk:  488\n",
      "current chunk:  489\n",
      "current chunk:  490\n",
      "current chunk:  491\n",
      "current chunk:  492\n",
      "current chunk:  493\n",
      "current chunk:  494\n",
      "current chunk:  495\n",
      "===================\n",
      "current chunk:  496\n",
      "current chunk:  497\n",
      "current chunk:  498\n",
      "current chunk:  499\n",
      "current chunk:  500\n",
      "current chunk:  501\n",
      "current chunk:  502\n",
      "current chunk:  503\n",
      "===================\n",
      "current chunk:  504\n",
      "current chunk:  505\n",
      "current chunk:  506\n",
      "current chunk:  507\n",
      "current chunk:  508\n",
      "current chunk:  509\n",
      "current chunk:  510\n",
      "current chunk:  511\n",
      "===================\n",
      "current chunk:  512\n",
      "current chunk:  513\n",
      "current chunk:  514\n",
      "current chunk:  515\n",
      "current chunk:  516\n",
      "current chunk:  517\n",
      "current chunk:  518\n",
      "current chunk:  519\n",
      "===================\n",
      "current chunk:  520\n",
      "current chunk:  521\n",
      "current chunk:  522\n",
      "current chunk:  523\n",
      "current chunk:  524\n",
      "current chunk:  525\n",
      "current chunk:  526\n",
      "current chunk:  527\n",
      "===================\n",
      "current chunk:  528\n",
      "current chunk:  529\n",
      "current chunk:  530\n",
      "current chunk:  531\n",
      "current chunk:  532\n",
      "current chunk:  533\n",
      "current chunk:  534\n",
      "current chunk:  535\n",
      "===================\n",
      "current chunk:  536\n",
      "current chunk:  537\n",
      "current chunk:  538\n",
      "current chunk:  539\n",
      "current chunk:  540\n",
      "current chunk:  541\n",
      "current chunk:  542\n",
      "current chunk:  543\n",
      "===================\n",
      "current chunk:  544\n",
      "current chunk:  545\n",
      "current chunk:  546\n",
      "current chunk:  547\n",
      "current chunk:  548\n",
      "current chunk:  549\n",
      "current chunk:  550\n",
      "current chunk:  551\n",
      "===================\n",
      "current chunk:  552\n",
      "current chunk:  553\n",
      "current chunk:  554\n",
      "current chunk:  555\n",
      "current chunk:  556\n",
      "current chunk:  557\n",
      "current chunk:  558\n",
      "current chunk:  559\n",
      "===================\n",
      "current chunk:  560\n",
      "current chunk:  561\n",
      "current chunk:  562\n",
      "current chunk:  563\n",
      "current chunk:  564\n",
      "current chunk:  565\n",
      "current chunk:  566\n",
      "current chunk:  567\n",
      "===================\n",
      "current chunk:  568\n",
      "current chunk:  569\n",
      "current chunk:  570\n",
      "current chunk:  571\n",
      "current chunk:  572\n",
      "current chunk:  573\n",
      "current chunk:  574\n",
      "current chunk:  575\n",
      "===================\n",
      "current chunk:  576\n",
      "current chunk:  577\n",
      "current chunk:  578\n",
      "current chunk:  579\n",
      "current chunk:  580\n",
      "current chunk:  581\n",
      "current chunk:  582\n",
      "current chunk:  583\n",
      "===================\n",
      "current chunk:  584\n",
      "current chunk:  585\n",
      "current chunk:  586\n",
      "current chunk:  587\n",
      "current chunk:  588\n",
      "current chunk:  589\n",
      "current chunk:  590\n",
      "current chunk:  591\n",
      "===================\n",
      "current chunk:  592\n",
      "current chunk:  593\n",
      "current chunk:  594\n",
      "current chunk:  595\n",
      "current chunk:  596\n",
      "current chunk:  597\n",
      "current chunk:  598\n",
      "current chunk:  599\n",
      "===================\n",
      "current chunk:  600\n",
      "current chunk:  601\n",
      "current chunk:  602\n",
      "current chunk:  603\n",
      "current chunk:  604\n",
      "current chunk:  605\n",
      "current chunk:  606\n",
      "current chunk:  607\n",
      "===================\n",
      "current chunk:  608\n",
      "current chunk:  609\n",
      "current chunk:  610\n",
      "current chunk:  611\n",
      "current chunk:  612\n",
      "current chunk:  613\n",
      "current chunk:  614\n",
      "current chunk:  615\n",
      "===================\n",
      "current chunk:  616\n",
      "current chunk:  617\n",
      "current chunk:  618\n",
      "current chunk:  619\n",
      "current chunk:  620\n",
      "current chunk:  621\n",
      "current chunk:  622\n",
      "current chunk:  623\n",
      "===================\n",
      "current chunk:  624\n",
      "current chunk:  625\n",
      "current chunk:  626\n",
      "current chunk:  627\n",
      "current chunk:  628\n",
      "current chunk:  629\n",
      "current chunk:  630\n",
      "current chunk:  631\n",
      "===================\n",
      "current chunk:  632\n",
      "current chunk:  633\n",
      "current chunk:  634\n",
      "current chunk:  635\n",
      "current chunk:  636\n",
      "current chunk:  637\n",
      "current chunk:  638\n",
      "current chunk:  639\n",
      "===================\n",
      "= = = dumping epoch: 3 = = =\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "exit dumping process\n",
      "current chunk:  640\n",
      "current chunk:  641\n",
      "current chunk:  642\n",
      "current chunk:  643\n",
      "current chunk:  644\n",
      "current chunk:  645\n",
      "current chunk:  646\n",
      "current chunk:  647\n",
      "===================\n",
      "current chunk:  648\n",
      "current chunk:  649\n",
      "current chunk:  650\n",
      "current chunk:  651\n",
      "current chunk:  652\n",
      "current chunk:  653\n",
      "current chunk:  654\n",
      "current chunk:  655\n",
      "===================\n",
      "current chunk:  656\n",
      "current chunk:  657\n",
      "current chunk:  658\n",
      "current chunk:  659\n",
      "current chunk:  660\n",
      "current chunk:  661\n",
      "current chunk:  662\n",
      "current chunk:  663\n",
      "===================\n",
      "current chunk:  664\n",
      "current chunk:  665\n",
      "current chunk:  666\n",
      "current chunk:  667\n",
      "current chunk:  668\n",
      "current chunk:  669\n",
      "current chunk:  670\n",
      "current chunk:  671\n",
      "===================\n",
      "current chunk:  672\n",
      "current chunk:  673\n",
      "current chunk:  674\n",
      "current chunk:  675\n",
      "current chunk:  676\n",
      "current chunk:  677\n",
      "current chunk:  678\n",
      "current chunk:  679\n",
      "===================\n",
      "current chunk:  680\n",
      "current chunk:  681\n",
      "current chunk:  682\n",
      "current chunk:  683\n",
      "current chunk:  684\n",
      "current chunk:  685\n",
      "current chunk:  686\n",
      "current chunk:  687\n",
      "===================\n",
      "current chunk:  688\n",
      "current chunk:  689\n",
      "current chunk:  690\n",
      "current chunk:  691\n",
      "current chunk:  692\n",
      "current chunk:  693\n",
      "current chunk:  694\n",
      "current chunk:  695\n",
      "===================\n",
      "current chunk:  696\n",
      "current chunk:  697\n",
      "current chunk:  698\n",
      "current chunk:  699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current chunk:  700\n",
      "current chunk:  701\n",
      "current chunk:  702\n",
      "current chunk:  703\n",
      "===================\n",
      "current chunk:  704\n",
      "current chunk:  705\n",
      "current chunk:  706\n",
      "current chunk:  707\n",
      "current chunk:  708\n",
      "current chunk:  709\n",
      "current chunk:  710\n",
      "current chunk:  711\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7c71a3332eba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# batch_data_parallel(table_path, qdtree_partition, chunk_size, used_dims, qdtree_hdfs, num_dims, dump_threshold, num_process)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print('finish qdtree data routing..')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mbatch_data_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkdtree_partition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkdtree_hdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdump_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_process\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'finish kdtree data routing..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d23781bdfcea>\u001b[0m in \u001b[0;36mbatch_data_parallel\u001b[0;34m(table_path, partition_path, chunk_size, used_dims, hdfs_path, num_dims, dump_threshold, num_process)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnum_process\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_process\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mparas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpid_data_dicts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_process\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mpid_data_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpara\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpara\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparas\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'==================='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# = = = Execution = = =\n",
    "# batch_data_parallel(table_path, nora_partition, chunk_size, used_dims, nora_hdfs, num_dims, dump_threshold, num_process)\n",
    "# print('finish nora data routing..')\n",
    "# batch_data_parallel(table_path, qdtree_partition, chunk_size, used_dims, qdtree_hdfs, num_dims, dump_threshold, num_process)\n",
    "# print('finish qdtree data routing..')\n",
    "batch_data_parallel(table_path, kdtree_partition, chunk_size, used_dims, kdtree_hdfs, num_dims, dump_threshold, num_process)\n",
    "print('finish kdtree data routing..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it seems the process of merging QdTree partitions are stuck, we re generate the merged data\n",
    "# but the below cannot work, it will also stuck at some point, I can't find out why\n",
    "\n",
    "# pool = Pool(processes = 3)\n",
    "\n",
    "# # totally 68 partitions for QdTree\n",
    "# # pids = [[k * 8 + i for i in range(8)] for k in range(num_process)]\n",
    "# # pids[-1] += [64, 65, 66, 67]\n",
    "\n",
    "# pids = [i for i in range(68)] # 0 - 67\n",
    "\n",
    "# batch = 0\n",
    "# while batch < 3:\n",
    "\n",
    "#     pids_each_process = [set(pids[batch*24+k*8: batch*24+(k+1)*8]) for k in range(3)]\n",
    "#     # totally 94 epochs\n",
    "#     paras = [[94, pids_each_process[k], qdtree_hdfs] for k in range(3)]\n",
    "#     pool.map(merge_parquets, [para for para in paras])\n",
    "#     batch += 1\n",
    "    \n",
    "# pool.close()\n",
    "# pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import pyarrow as pa\n",
    "# import pyarrow.parquet as pq\n",
    "# import numpy as np\n",
    "\n",
    "# pids = [i for i in range(68)] # 0 - 67\n",
    "# batches = 94\n",
    "# hdfs_path = qdtree_hdfs\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# # using single process to handle data merge\n",
    "# fs = pa.hdfs.connect()\n",
    "# for pid in pids:\n",
    "#     parquets = []\n",
    "#     print('= = = process pid: ', pid, '= = =')\n",
    "#     for batch in range(batches):\n",
    "#         path = hdfs_path + str(batch) + '/partition_' + str(pid)+'.parquet'\n",
    "#         print(batch)\n",
    "#         try:\n",
    "#             par = pq.read_table(path)\n",
    "#             parquets.append(par)\n",
    "#         except:\n",
    "#             continue\n",
    "#     merged_parquet = pa.concat_tables(parquets)\n",
    "#     merge_path = hdfs_path + 'merged/partition_' + str(pid)+'.parquet'\n",
    "#     fw = fs.open(merge_path, 'wb')\n",
    "#     pq.write_table(merged_parquet, fw)\n",
    "#     fw.close()\n",
    "# print('exit merge process')\n",
    "\n",
    "# end_time = time.time()\n",
    "# print('time usage: ', end_time - start_time) # 2347s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
